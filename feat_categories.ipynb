{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf9f734",
   "metadata": {},
   "source": [
    "# Categories: Feature Extraction and Similarity Computation\n",
    "\n",
    "We now focus on the category of each video.\n",
    "\n",
    "## Stages of Implementation:\n",
    "1. Data Loading and Pre-processing\n",
    "2. One Hot Encoding of Categories\n",
    "3. Cosine Similarity Computation\n",
    "4. Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d525311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 13)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "train_data = pd.read_csv(\"dataset/kuairec/data/big_matrix.csv\")\n",
    "test_data = pd.read_csv(\"dataset/kuairec/data/small_matrix.csv\")\n",
    "categories = pd.read_csv(\"dataset/kuairec/data/item_categories.csv\")\n",
    "\n",
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)\n",
    "train_data.drop_duplicates(inplace=True)\n",
    "test_data.drop_duplicates(inplace=True)\n",
    "train_data = train_data[train_data[\"timestamp\"] >= 0]\n",
    "test_data = test_data[test_data[\"timestamp\"] >= 0]\n",
    "\n",
    "# Construct item feature matrix\n",
    "items = train_data.groupby(\"video_id\")\n",
    "items = items.agg(\n",
    "    {\n",
    "        \"user_id\": \"count\",\n",
    "        \"video_duration\": \"mean\",\n",
    "        \"timestamp\": \"max\",\n",
    "        \"watch_ratio\": \"mean\",\n",
    "        \"time\": \"max\",\n",
    "        \"date\": \"max\",\n",
    "    }\n",
    ")\n",
    "items.drop(columns=[\"user_id\"], inplace=True)\n",
    "items.drop(columns=[\"timestamp\"], inplace=True)\n",
    "items.drop(columns=[\"watch_ratio\"], inplace=True)\n",
    "items.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "# videos represent by their categories\n",
    "import ast\n",
    "\n",
    "for i in range (31):\n",
    "    categories['category_' + str(i)] = 0\n",
    "\n",
    "categories['feat'] = categories['feat'].apply(ast.literal_eval)\n",
    "for index, row in categories.iterrows():\n",
    "    # Get the list of features for the current row\n",
    "    features = row['feat']\n",
    "\n",
    "    # Set the corresponding category columns to 1\n",
    "    for feat in features:\n",
    "        col_name = f'category_{feat}'\n",
    "        if col_name in categories.columns:\n",
    "            categories.at[index, col_name] = 1\n",
    "categories.drop(columns=['feat'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f548b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "item_similarity = cosine_similarity(categories.drop(columns=['video_id']), categories.drop(columns=['video_id']))\n",
    "item_similarity_df = pd.DataFrame(\n",
    "    item_similarity,\n",
    "    index=categories['video_id'],\n",
    "    columns=categories['video_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c101871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def generate_top_n_recommendations_from_logs(interactions_df, cosine_sim, video_ids, N=10, min_watch_ratio=0.5):\n",
    "    video_ids = pd.Index(video_ids)  # FIX HERE\n",
    "\n",
    "    filtered = interactions_df[interactions_df['watch_ratio'] >= min_watch_ratio]\n",
    "    user_histories = filtered.groupby('user_id')['video_id'].apply(set).to_dict()\n",
    "\n",
    "    recommendations = {}\n",
    "\n",
    "    for user, watched in user_histories.items():\n",
    "        watched_indices = [video_ids.get_loc(v) for v in watched if v in video_ids]\n",
    "        if not watched_indices:\n",
    "            recommendations[user] = []\n",
    "            continue\n",
    "\n",
    "        sim_scores = np.array(np.sum(cosine_sim[watched_indices], axis=0)).ravel()\n",
    "\n",
    "        for v in watched:\n",
    "            if v in video_ids:\n",
    "                sim_scores[video_ids.get_loc(v)] = -1\n",
    "\n",
    "        top_indices = np.argsort(sim_scores)[::-1][:N]\n",
    "        top_videos = video_ids[top_indices].tolist()\n",
    "        recommendations[user] = top_videos\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90df76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_ground_truth(interactions_df, min_watch_ratio=0.75):\n",
    "    \"\"\"\n",
    "    Return user -> set of relevant video_ids from test interactions.\n",
    "    \"\"\"\n",
    "    filtered = interactions_df[interactions_df['watch_ratio'] >= min_watch_ratio]\n",
    "    return filtered.groupby('user_id')['video_id'].apply(set).to_dict()\n",
    "\n",
    "test_truth = prepare_test_ground_truth(\n",
    "    interactions_df=test_data,\n",
    "    min_watch_ratio=0.75\n",
    ")\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "def hit_rate_log(recommendations, test_ground_truth):\n",
    "    hits, total = 0, 0\n",
    "    for user, recs in recommendations.items():\n",
    "        true_items = test_ground_truth.get(user, set())\n",
    "        hits += len(set(recs) & true_items)\n",
    "        total += len(true_items)\n",
    "    return hits / total if total else 0\n",
    "\n",
    "def precision_at_k_log(recommendations, test_ground_truth, k=10):\n",
    "    precisions = []\n",
    "    for user, recs in recommendations.items():\n",
    "        true_items = test_ground_truth.get(user, set())\n",
    "        if not true_items:\n",
    "            continue\n",
    "        hits = len(set(recs[:k]) & true_items)\n",
    "        precisions.append(hits / k)\n",
    "    return np.mean(precisions) if precisions else 0\n",
    "\n",
    "def ndcg_at_k_log(recommendations, test_ground_truth, k=10):\n",
    "    ndcgs = []\n",
    "    for user, recs in recommendations.items():\n",
    "        true_items = test_ground_truth.get(user, set())\n",
    "        if not true_items:\n",
    "            continue\n",
    "        y_true = [1 if vid in true_items else 0 for vid in recs[:k]]\n",
    "        y_score = list(range(k, 0, -1))\n",
    "        ndcgs.append(ndcg_score([y_true], [y_score]))\n",
    "    return np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "def mrr_log(recommendations, test_ground_truth):\n",
    "    rr = []\n",
    "    for user, recs in recommendations.items():\n",
    "        true_items = test_ground_truth.get(user, set())\n",
    "        if not true_items:\n",
    "            continue\n",
    "        for rank, vid in enumerate(recs, 1):\n",
    "            if vid in true_items:\n",
    "                rr.append(1 / rank)\n",
    "                break\n",
    "        else:\n",
    "            rr.append(0)\n",
    "    return np.mean(rr) if rr else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49cac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 for category sim: 0.2243\n",
      "NDCG@10 for category sim: 0.5511\n",
      "MRR@10 for category sim: 0.4385\n",
      "--------------------------------------------------\n",
      "Precision@20 for category sim: 0.1934\n",
      "NDCG@20 for category sim: 0.5742\n",
      "MRR@20 for category sim: 0.4447\n",
      "--------------------------------------------------\n",
      "Precision@50 for category sim: 0.1596\n",
      "NDCG@50 for category sim: 0.5768\n",
      "MRR@50 for category sim: 0.4458\n",
      "--------------------------------------------------\n",
      "Precision@100 for category sim: 0.1747\n",
      "NDCG@100 for category sim: 0.5849\n",
      "MRR@100 for category sim: 0.4458\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "N = [10, 20, 50, 100]\n",
    "for n in N:\n",
    "    recs_train_category = generate_top_n_recommendations_from_logs(\n",
    "        interactions_df=train_data,\n",
    "        cosine_sim=item_similarity,\n",
    "        video_ids=pd.Index(train_data['video_id'].unique()),\n",
    "        N=n,\n",
    "        min_watch_ratio=0.75\n",
    "    )\n",
    "\n",
    "    prec  = precision_at_k_log(recs_train_category, test_truth, k=n)\n",
    "    ndcg = ndcg_at_k_log(recs_train_category, test_truth, k=n)\n",
    "    mrr = mrr_log(recs_train_category, test_truth)\n",
    "    print(f\"Precision@{n} for category sim: {prec:.4f}\")\n",
    "    print(f\"NDCG@{n} for category sim: {ndcg:.4f}\")\n",
    "    print(f\"MRR@{n} for category sim: {mrr:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
