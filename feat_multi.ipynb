{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf9f734",
   "metadata": {},
   "source": [
    "# Caption: Feature Extraction and Similarity Computation for Content-Based Recommendation Systems\n",
    "\n",
    "## Stages of Implementation:\n",
    "1. Loading of the kuairec_caption_category.csv dataset\n",
    "2. Cleaning of the chinese text\n",
    "3. TF-IDF Vectorization\n",
    "4. Cosine Similarity Calculation\n",
    "5. Metrics Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c097e81",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d525311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in captions: 6097\n",
      "Content features shape: (10728, 10)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 13)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "train_data = pd.read_csv(\"dataset/kuairec/data/big_matrix.csv\")\n",
    "test_data = pd.read_csv(\"dataset/kuairec/data/small_matrix.csv\")\n",
    "categories = pd.read_csv(\"dataset/kuairec/data/item_categories.csv\")\n",
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)\n",
    "train_data.drop_duplicates(inplace=True)\n",
    "test_data.drop_duplicates(inplace=True)\n",
    "train_data = train_data[train_data[\"timestamp\"] >= 0]\n",
    "test_data = test_data[test_data[\"timestamp\"] >= 0]\n",
    "\n",
    "# Construct item feature matrix\n",
    "items = train_data.groupby(\"video_id\")\n",
    "items = items.agg(\n",
    "    {\n",
    "        \"user_id\": \"count\",\n",
    "        \"video_duration\": \"mean\",\n",
    "        \"timestamp\": \"max\",\n",
    "        \"watch_ratio\": \"mean\",\n",
    "        \"time\": \"max\",\n",
    "        \"date\": \"max\",\n",
    "    }\n",
    ")\n",
    "items.drop(columns=[\"user_id\"], inplace=True)\n",
    "items.drop(columns=[\"timestamp\"], inplace=True)\n",
    "items.drop(columns=[\"watch_ratio\"], inplace=True)\n",
    "items.drop(columns=[\"date\"], inplace=True)\n",
    "categories.drop(columns=[\"feat\"], inplace=True)\n",
    "\n",
    "captions = pd.read_csv(\n",
    "    \"dataset/kuairec/data/kuairec_caption_category.csv\",\n",
    "    encoding='utf-8',\n",
    "    na_values=[],\n",
    "    keep_default_na=False,\n",
    "    on_bad_lines='skip',   # skip problematic rows\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "captions = captions.dropna()\n",
    "captions = captions.drop_duplicates()\n",
    "# print first_level_category_name != UNKNOWN\n",
    "captions = captions[captions[\"first_level_category_name\"] != \"UNKNOWN\"]\n",
    "# get all the non empty tags\n",
    "captions = captions[captions[\"topic_tag\"] != \"[]\"]\n",
    "# print number of lines\n",
    "print(f\"Number of lines in captions: {captions.shape[0]}\")\n",
    "# cast the video_id to int\n",
    "captions['video_id'] = captions['video_id'].astype(int)\n",
    "# cast the video_id to int\n",
    "\n",
    "# Merge captions with item features\n",
    "categories = pd.merge(categories, captions, left_on='video_id', right_on='video_id', how='left')\n",
    "\n",
    "# Display the merged dataset\n",
    "print(f\"Content features shape: {categories.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c21ca",
   "metadata": {},
   "source": [
    "## Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90df8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>manual_cover_text</th>\n",
       "      <th>caption</th>\n",
       "      <th>topic_tag</th>\n",
       "      <th>first_level_category_id</th>\n",
       "      <th>first_level_category_name</th>\n",
       "      <th>second_level_category_id</th>\n",
       "      <th>second_level_category_name</th>\n",
       "      <th>third_level_category_id</th>\n",
       "      <th>third_level_category_name</th>\n",
       "      <th>clean_caption</th>\n",
       "      <th>clean_manual_cover</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>五爱街最美美女 一天1q</td>\n",
       "      <td>#搞笑 #感谢快手我要上热门 #五爱市场 这真是完美搭配啊！</td>\n",
       "      <td>[五爱市场,感谢快手我要上热门,搞笑]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>时尚</td>\n",
       "      <td>737.0</td>\n",
       "      <td>营销售卖</td>\n",
       "      <td>2596.0</td>\n",
       "      <td>女装</td>\n",
       "      <td>搞笑 感谢快手我要上热门 五爱市场 这真是完美搭配啊</td>\n",
       "      <td>五爱街最美美女 一天1q</td>\n",
       "      <td>搞笑 感谢快手我要上热门 五爱市场 这真是完美搭配啊 五爱街最美美女 一天1q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id manual_cover_text                         caption  \\\n",
       "0         0               NaN                             NaN   \n",
       "1         1               NaN                             NaN   \n",
       "2         2               NaN                             NaN   \n",
       "3         3               NaN                             NaN   \n",
       "4         4      五爱街最美美女 一天1q  #搞笑 #感谢快手我要上热门 #五爱市场 这真是完美搭配啊！   \n",
       "\n",
       "             topic_tag  first_level_category_id first_level_category_name  \\\n",
       "0                  NaN                      NaN                       NaN   \n",
       "1                  NaN                      NaN                       NaN   \n",
       "2                  NaN                      NaN                       NaN   \n",
       "3                  NaN                      NaN                       NaN   \n",
       "4  [五爱市场,感谢快手我要上热门,搞笑]                      5.0                        时尚   \n",
       "\n",
       "   second_level_category_id second_level_category_name  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                     737.0                       营销售卖   \n",
       "\n",
       "   third_level_category_id third_level_category_name  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                       NaN   \n",
       "2                      NaN                       NaN   \n",
       "3                      NaN                       NaN   \n",
       "4                   2596.0                        女装   \n",
       "\n",
       "                clean_caption clean_manual_cover  \\\n",
       "0                                                  \n",
       "1                                                  \n",
       "2                                                  \n",
       "3                                                  \n",
       "4  搞笑 感谢快手我要上热门 五爱市场 这真是完美搭配啊       五爱街最美美女 一天1q   \n",
       "\n",
       "                             combined_text  \n",
       "0                                           \n",
       "1                                           \n",
       "2                                           \n",
       "3                                           \n",
       "4  搞笑 感谢快手我要上热门 五爱市场 这真是完美搭配啊 五爱街最美美女 一天1q  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or text == '' or text == 'UNKNOWN':\n",
    "        return ''\n",
    "        \n",
    "    # Keep original Chinese characters but remove punctuation and convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s\\u4e00-\\u9fff]', '', text.lower())\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning to caption and manual_cover_text\n",
    "categories['clean_caption'] = categories['caption'].apply(clean_text)\n",
    "categories['clean_manual_cover'] = categories['manual_cover_text'].apply(clean_text)\n",
    "\n",
    "# Combine text features\n",
    "categories['combined_text'] = categories['clean_caption'] + ' ' + categories['clean_manual_cover']\n",
    "categories['combined_text'] = categories['combined_text'].str.strip()\n",
    "\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f2dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064643/3529211327.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sub_categories['combined_text'].replace('', np.nan, inplace=True)\n",
      "/tmp/ipykernel_1064643/3529211327.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_categories['combined_text'].replace('', np.nan, inplace=True)\n",
      "/tmp/ipykernel_1064643/3529211327.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sub_categories['combined_text'].fillna(' ', inplace=True)\n",
      "/tmp/ipykernel_1064643/3529211327.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_categories['combined_text'].fillna(' ', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF features: (10728, 1001)\n"
     ]
    }
   ],
   "source": [
    "sub_categories = categories[['video_id', 'combined_text', 'topic_tag']]\n",
    "categories.drop(columns=[\"topic_tag\"], inplace=True)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Apply TF-IDF to the combined text\n",
    "# Replace empty strings with NaN and then with a space to avoid vectorizer issues\n",
    "sub_categories['combined_text'].replace('', np.nan, inplace=True)\n",
    "sub_categories['combined_text'].fillna(' ', inplace=True)\n",
    "\n",
    "video_ids = sub_categories['video_id'].reset_index(drop=True)\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "# For Chinese text, we'll use character-level n-grams\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='char_wb',  # Character n-grams with word boundaries\n",
    "    ngram_range=(1, 3),  # Use 1 to 3-character n-grams\n",
    "    max_features=1000,   # Limit features to manage dimensionality\n",
    "    min_df=5,            # Minimum document frequency\n",
    "    max_df=0.7          # Maximum document frequency\n",
    ")\n",
    "\n",
    "text_features = tfidf.fit_transform(sub_categories['combined_text'])\n",
    "\n",
    "# Convert to DataFrame and add video_id\n",
    "text_feature_names = ['text_' + str(i) for i in range(text_features.shape[1])]\n",
    "tfidf_df = pd.DataFrame(\n",
    "    text_features.toarray(),\n",
    "    columns=text_feature_names\n",
    ")\n",
    "tfidf_df['video_id'] = video_ids\n",
    "\n",
    "# Optionally, move video_id to the front\n",
    "cols = ['video_id'] + [c for c in tfidf_df.columns if c != 'video_id']\n",
    "tfidf_df = tfidf_df[cols]\n",
    "\n",
    "# Done!\n",
    "print(f\"Shape of TF-IDF features: {tfidf_df.shape}\")\n",
    "# Merge TF-IDF features with categories\n",
    "categories = pd.merge(categories, tfidf_df, on='video_id', how='left')\n",
    "# make vidoe_id as index\n",
    "# find column where type is string\n",
    "string_columns = categories.select_dtypes(include=['object']).columns\n",
    "# drop all string columns\n",
    "categories.drop(columns=string_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34afb9a6",
   "metadata": {},
   "source": [
    "## Cosine Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f548b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# replace NaN with 0\n",
    "categories.fillna(0, inplace=True)\n",
    "item_similarity = cosine_similarity(categories.drop(columns=['video_id']), categories.drop(columns=['video_id']))\n",
    "item_similarity_df = pd.DataFrame(\n",
    "    item_similarity,\n",
    "    index=categories['video_id'],\n",
    "    columns=categories['video_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c101871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def generate_top_n_recommendations_from_logs(interactions_df, cosine_sim, video_ids, N=10, min_watch_ratio=0.5):\n",
    "    video_ids = pd.Index(video_ids)  # FIX HERE\n",
    "\n",
    "    filtered = interactions_df[interactions_df['watch_ratio'] >= min_watch_ratio]\n",
    "    user_histories = filtered.groupby('user_id')['video_id'].apply(set).to_dict()\n",
    "\n",
    "    recommendations = {}\n",
    "\n",
    "    for user, watched in user_histories.items():\n",
    "        watched_indices = [video_ids.get_loc(v) for v in watched if v in video_ids]\n",
    "        if not watched_indices:\n",
    "            recommendations[user] = []\n",
    "            continue\n",
    "\n",
    "        sim_scores = np.array(np.sum(cosine_sim[watched_indices], axis=0)).ravel()\n",
    "\n",
    "        for v in watched:\n",
    "            if v in video_ids:\n",
    "                sim_scores[video_ids.get_loc(v)] = -1\n",
    "\n",
    "        top_indices = np.argsort(sim_scores)[::-1][:N]\n",
    "        top_videos = video_ids[top_indices].tolist()\n",
    "        recommendations[user] = top_videos\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# video_ids = categories['video_id'].reset_index(drop=True)  # Must match cosine_sim\n",
    "# video_id_set = set(video_ids)\n",
    "# N = 10\n",
    "# recs_train_category = generate_top_n_recommendations_from_logs(\n",
    "#     interactions_df=train_data,\n",
    "#     cosine_sim=item_similarity,\n",
    "#     # video_ids=categories['video_id'].reset_index(drop=True),\n",
    "#     video_ids=pd.Index(train_data['video_id'].unique()),\n",
    "#     N=N,\n",
    "#     min_watch_ratio=0.75\n",
    "# )\n",
    "\n",
    "def prepare_test_ground_truth(interactions_df, min_watch_ratio=0.75):\n",
    "    \"\"\"\n",
    "    Return user -> set of relevant video_ids from test interactions.\n",
    "    \"\"\"\n",
    "    filtered = interactions_df[interactions_df['watch_ratio'] >= min_watch_ratio]\n",
    "    return filtered.groupby('user_id')['video_id'].apply(set).to_dict()\n",
    "\n",
    "test_truth = prepare_test_ground_truth(\n",
    "    interactions_df=test_data,\n",
    "    min_watch_ratio=0.75\n",
    ")\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "def hit_rate_log(recommendations, test_ground_truth):\n",
    "    hits, total = 0, 0\n",
    "    for user, recs in recommendations.items():\n",
    "        true_items = test_ground_truth.get(user, set())\n",
    "        hits += len(set(recs) & true_items)\n",
    "        total += len(true_items)\n",
    "    return hits / total if total else 0\n",
    "\n",
    "def precision_at_k_log(recommendations, test_ground_truth, k=10):\n",
    "    precisions = []\n",
    "    for user, recs in recommendations.items():\n",
    "        true_items = test_ground_truth.get(user, set())\n",
    "        if not true_items:\n",
    "            continue\n",
    "        hits = len(set(recs[:k]) & true_items)\n",
    "        precisions.append(hits / k)\n",
    "    return np.mean(precisions) if precisions else 0\n",
    "\n",
    "def ndcg_at_k_log(recommendations, test_ground_truth, k=10):\n",
    "    ndcgs = []\n",
    "    for user, recs in recommendations.items():\n",
    "        true_items = test_ground_truth.get(user, set())\n",
    "        if not true_items:\n",
    "            continue\n",
    "        y_true = [1 if vid in true_items else 0 for vid in recs[:k]]\n",
    "        y_score = list(range(k, 0, -1))\n",
    "        ndcgs.append(ndcg_score([y_true], [y_score]))\n",
    "    return np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "def mrr_log(recommendations, test_ground_truth):\n",
    "    rr = []\n",
    "    for user, recs in recommendations.items():\n",
    "        true_items = test_ground_truth.get(user, set())\n",
    "        if not true_items:\n",
    "            continue\n",
    "        for rank, vid in enumerate(recs, 1):\n",
    "            if vid in true_items:\n",
    "                rr.append(1 / rank)\n",
    "                break\n",
    "        else:\n",
    "            rr.append(0)\n",
    "    return np.mean(rr) if rr else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21181a",
   "metadata": {},
   "source": [
    "## Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71459053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 for category sim: 0.1748\n",
      "NDCG@10 for category sim: 0.4423\n",
      "MRR@10 for category sim: 0.2832\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "N = [10, 20, 50, 100, 500]\n",
    "for n in N:\n",
    "    recs_train_category = generate_top_n_recommendations_from_logs(\n",
    "        interactions_df=train_data,\n",
    "        cosine_sim=item_similarity,\n",
    "        video_ids=pd.Index(train_data['video_id'].unique()),\n",
    "        N=n,\n",
    "        min_watch_ratio=0.75\n",
    "    )\n",
    "\n",
    "    prec  = precision_at_k_log(recs_train_category, test_truth, k=n)\n",
    "    ndcg = ndcg_at_k_log(recs_train_category, test_truth, k=n)\n",
    "    mrr = mrr_log(recs_train_category, test_truth)\n",
    "    print(f\"Precision@{n} for category sim: {prec:.4f}\")\n",
    "    print(f\"NDCG@{n} for category sim: {ndcg:.4f}\")\n",
    "    print(f\"MRR@{n} for category sim: {mrr:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
